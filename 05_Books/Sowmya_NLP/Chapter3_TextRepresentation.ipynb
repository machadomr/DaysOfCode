{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prescribed-london",
   "metadata": {},
   "source": [
    "**Chapter 3 â€“ Text Representation**\n",
    "#### I will be following the chapter activities!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-petersburg",
   "metadata": {},
   "source": [
    "### One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-trademark",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\"Dog bites man.\", \"Man bites dog.\", \"Dog eats meat.\", \"Man eats food.\"]\n",
    "processed_docs = [doc.lower().replace(\".\",\"\") for doc in documents]\n",
    "processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-theory",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the vocabulary\n",
    "vocab = {}\n",
    "count = 0\n",
    "for doc in processed_docs:\n",
    "    for word in doc.split():\n",
    "        if word not in vocab:\n",
    "            count = count +1\n",
    "            vocab[word] = count\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-invitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get one hot representation for any string based on this vocabulary. \n",
    "#If the word exists in the vocabulary, its representation is returned. \n",
    "#If not, a list of zeroes is returned for that word. \n",
    "def get_onehot_vector(somestring):\n",
    "    onehot_encoded = []\n",
    "    for word in somestring.split():\n",
    "        temp = [0]*len(vocab)\n",
    "        if word in vocab:\n",
    "            temp[vocab[word]-1] = 1 # -1 is to take care of the fact indexing in array starts from 0 and not 1\n",
    "        onehot_encoded.append(temp)\n",
    "    return onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-mason",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(processed_docs[1])\n",
    "get_onehot_vector(processed_docs[1]) #one hot representation for a text from our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_onehot_vector(\"man and dog are good\") \n",
    "#one hot representation for a random text, using the above vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-aaron",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_onehot_vector(\"man and man are good\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-dream",
   "metadata": {},
   "source": [
    "#### One-hot encoding with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-aerospace",
   "metadata": {},
   "outputs": [],
   "source": [
    "S1 = 'dog bites man'\n",
    "S2 = 'man bites dog'\n",
    "S3 = 'dog eats meat'\n",
    "S4 = 'man eats food'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "data = [S1.split(), S2.split(), S3.split(), S4.split()]\n",
    "values = data[0]+data[1]+data[2]+data[3]\n",
    "print(\"The data: \",values)\n",
    "\n",
    "#Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print(\"Label Encoded:\",integer_encoded)\n",
    "\n",
    "#One-Hot Encoding\n",
    "onehot_encoder = OneHotEncoder()\n",
    "onehot_encoded = onehot_encoder.fit_transform(data).toarray()\n",
    "print(\"Onehot Encoded Matrix:\\n\",onehot_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-uganda",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-limitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\"Dog bites man.\", \"Man bites dog.\", \"Dog eats meat.\", \"Man eats food.\"] #Same as the earlier notebook\n",
    "processed_docs = [doc.lower().replace(\".\",\"\") for doc in documents]\n",
    "processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#look at the documents list\n",
    "print(\"Our corpus: \", processed_docs)\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "#Build a BOW representation for the corpus\n",
    "bow_rep = count_vect.fit_transform(processed_docs)\n",
    "\n",
    "#Look at the vocabulary mapping\n",
    "print(\"Our vocabulary: \", count_vect.vocabulary_)\n",
    "\n",
    "#see the BOW rep for first 2 documents\n",
    "print(\"BoW representation for 'dog bites man': \", bow_rep[0].toarray())\n",
    "print(\"BoW representation for 'man bites dog: \",bow_rep[1].toarray())\n",
    "\n",
    "#Get the representation using this vocabulary, for a new text\n",
    "temp = count_vect.transform([\"dog and dog are friends\"])\n",
    "print(\"Bow representation for 'dog and dog are friends':\", temp.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BoW with binary vectors\n",
    "count_vect = CountVectorizer(binary=True)\n",
    "bow_rep_bin = count_vect.fit_transform(processed_docs)\n",
    "temp = count_vect.transform([\"dog and dog are friends\"])\n",
    "print(\"Bow representation for 'dog and dog are friends':\", temp.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-question",
   "metadata": {},
   "source": [
    "### Bag of N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-voltage",
   "metadata": {},
   "outputs": [],
   "source": [
    "#our corpus\n",
    "documents = [\"Dog bites man.\", \"Man bites dog.\", \"Dog eats meat.\", \"Man eats food.\"]\n",
    "\n",
    "processed_docs = [doc.lower().replace(\".\",\"\") for doc in documents]\n",
    "processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Ngram vectorization example with count vectorizer and uni, bi, trigrams\n",
    "count_vect = CountVectorizer(ngram_range=(1,3))\n",
    "\n",
    "#Build a BOW representation for the corpus\n",
    "bow_rep = count_vect.fit_transform(processed_docs)\n",
    "\n",
    "#Look at the vocabulary mapping\n",
    "print(\"Our vocabulary: \", count_vect.vocabulary_)\n",
    "\n",
    "#see the BOW rep for first 2 documents\n",
    "print(\"BoW representation for 'dog bites man': \", bow_rep[0].toarray())\n",
    "print(\"BoW representation for 'man bites dog: \",bow_rep[1].toarray())\n",
    "\n",
    "#Get the representation using this vocabulary, for a new text\n",
    "temp = count_vect.transform([\"dog and dog are friends\"])\n",
    "\n",
    "print(\"Bow representation for 'dog and dog are friends':\", temp.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-recipient",
   "metadata": {},
   "source": [
    "### TD-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-maximum",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\"Dog bites man.\", \"Man bites dog.\", \"Dog eats meat.\", \"Man eats food.\"]\n",
    "processed_docs = [doc.lower().replace(\".\",\"\") for doc in documents]\n",
    "processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-enough",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "bow_rep_tfidf = tfidf.fit_transform(processed_docs)\n",
    "\n",
    "#IDF for all words in the vocabulary\n",
    "print(\"IDF for all words in the vocabulary\",tfidf.idf_)\n",
    "print(\"-\"*10)\n",
    "#All words in the vocabulary.\n",
    "print(\"All words in the vocabulary\",tfidf.get_feature_names())\n",
    "print(\"-\"*10)\n",
    "\n",
    "#TFIDF representation for all documents in our corpus \n",
    "print(\"TFIDF representation for all documents in our corpus\\n\",bow_rep_tfidf.toarray()) \n",
    "print(\"-\"*10)\n",
    "\n",
    "temp = tfidf.transform([\"dog and man are friends\"])\n",
    "print(\"Tfidf representation for 'dog and man are friends':\\n\", temp.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-government",
   "metadata": {},
   "source": [
    "### Pre-trained word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -P /tmp/input/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-commander",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings #This module ignores the various types of warnings generated\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "import os #This module provides a way of using operating system dependent functionality\n",
    "\n",
    "import psutil #This module helps in retrieving information on running processes and system resource utilization\n",
    "process = psutil.Process(os.getpid())\n",
    "from psutil import virtual_memory\n",
    "mem = virtual_memory()\n",
    "\n",
    "import time #This module is used to calculate the time  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "pretrainedpath = '/tmp/input/GoogleNews-vectors-negative300.bin.gz'\n",
    "\n",
    "#Load W2V model. This will take some time, but it is a one time effort! \n",
    "pre = process.memory_info().rss\n",
    "print(\"Memory used in GB before Loading the Model: %0.2f\"%float(pre/(10**9))) #Check memory usage before loading the model\n",
    "print('-'*10)\n",
    "\n",
    "start_time = time.time() #Start the timer\n",
    "ttl = mem.total #Toal memory available\n",
    "\n",
    "w2v_model = KeyedVectors.load_word2vec_format(pretrainedpath, binary=True) #load the model\n",
    "print(\"%0.2f seconds taken to load\"%float(time.time() - start_time)) #Calculate the total time elapsed since starting the timer\n",
    "print('-'*10)\n",
    "\n",
    "print('Finished loading Word2Vec')\n",
    "print('-'*10)\n",
    "\n",
    "post = process.memory_info().rss\n",
    "print(\"Memory used in GB after Loading the Model: {:.2f}\".format(float(post/(10**9)))) #Calculate the memory used after loading the model\n",
    "print('-'*10)\n",
    "\n",
    "print(\"Percentage increase in memory usage: {:.2f}% \".format(float((post/pre)*100))) #Percentage increase in memory after loading the model\n",
    "print('-'*10)\n",
    "\n",
    "print(\"Numver of words in vocablulary: \",len(w2v_model.vocab)) #Number of words in the vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-kitty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us examine the model by knowing what the most similar words are, for a given word!\n",
    "w2v_model.most_similar('beautiful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-local",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us try with another word! \n",
    "w2v_model.most_similar('toronto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the vector representation for a word? \n",
    "w2v_model['computer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-basket",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What if I am looking for a word that is not in this vocabulary?\n",
    "w2v_model['practicalnlp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-bridal",
   "metadata": {},
   "source": [
    "### Document Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-first",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading en_core_web_sm, assuming spacy is already installed\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-handle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import spacy and load the model\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\") #here nlp object refers to the 'en_core_web_sm' language model instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assume each sentence in documents corresponds to a separate document.\n",
    "documents = [\"Dog bites man.\", \"Man bites dog.\", \"Dog eats meat.\", \"Man eats food.\"]\n",
    "processed_docs = [doc.lower().replace(\".\",\"\") for doc in documents]\n",
    "processed_docs\n",
    "\n",
    "print(\"Document After Pre-Processing:\",processed_docs)\n",
    "\n",
    "\n",
    "#Iterate over each document and initiate an nlp instance.\n",
    "for doc in processed_docs:\n",
    "    doc_nlp = nlp(doc) #creating a spacy \"Doc\" object which is a container for accessing linguistic annotations. \n",
    "    \n",
    "    print(\"-\"*30)\n",
    "    print(\"Average Vector of '{}'\\n\".format(doc),doc_nlp.vector)#this gives the average vector of each document\n",
    "    for token in doc_nlp:\n",
    "        print()\n",
    "        print(token.text,token.vector)#this gives the text of each word in the doc and their respective vectors.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-headquarters",
   "metadata": {},
   "source": [
    "### Doc3Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-reducing",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\"dog bites man\",\n",
    "        \"man bites dog\",\n",
    "        \"dog eats meat\",\n",
    "        \"man eats food\"]\n",
    "\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(word.lower()), tags=[str(i)]) for i, word in enumerate(data)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-pontiac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-rough",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dbow\n",
    "model_dbow = Doc2Vec(tagged_data,vector_size=20, min_count=1, epochs=2,dm=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_dbow.infer_vector(['man','eats','food']))#feature vector of man eats food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dbow.wv.most_similar(\"man\",topn=5)#top 5 most simlar words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dbow.wv.n_similarity([\"dog\"],[\"man\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dm\n",
    "model_dm = Doc2Vec(tagged_data, min_count=1, vector_size=20, epochs=2,dm=1)\n",
    "\n",
    "print(\"Inference Vector of man eats food\\n \",model_dm.infer_vector(['man','eats','food']))\n",
    "\n",
    "print(\"Most similar words to man in our corpus\\n\",model_dm.wv.most_similar(\"man\",topn=5))\n",
    "print(\"Similarity between man and dog: \",model_dm.wv.n_similarity([\"dog\"],[\"man\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-zealand",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dm.wv.n_similarity(['covid'],['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-sierra",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-worker",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-weekly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-speed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-batch",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
