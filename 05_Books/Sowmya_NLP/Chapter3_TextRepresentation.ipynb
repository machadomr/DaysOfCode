{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "black-temple",
   "metadata": {},
   "source": [
    "**Chapter 3 – Text Representation**\n",
    "#### I will be following the chapter activities!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-bread",
   "metadata": {},
   "source": [
    "### One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dated-recorder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog bites man', 'man bites dog', 'dog eats meat', 'man eats food']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [\"Dog bites man.\", \"Man bites dog.\", \"Dog eats meat.\", \"Man eats food.\"]\n",
    "processed_docs = [doc.lower().replace(\".\",\"\") for doc in documents]\n",
    "processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "violent-consent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dog': 1, 'bites': 2, 'man': 3, 'eats': 4, 'meat': 5, 'food': 6}\n"
     ]
    }
   ],
   "source": [
    "#Build the vocabulary\n",
    "vocab = {}\n",
    "count = 0\n",
    "for doc in processed_docs:\n",
    "    for word in doc.split():\n",
    "        if word not in vocab:\n",
    "            count = count +1\n",
    "            vocab[word] = count\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "third-south",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get one hot representation for any string based on this vocabulary. \n",
    "#If the word exists in the vocabulary, its representation is returned. \n",
    "#If not, a list of zeroes is returned for that word. \n",
    "def get_onehot_vector(somestring):\n",
    "    onehot_encoded = []\n",
    "    for word in somestring.split():\n",
    "        temp = [0]*len(vocab)\n",
    "        if word in vocab:\n",
    "            temp[vocab[word]-1] = 1 # -1 is to take care of the fact indexing in array starts from 0 and not 1\n",
    "        onehot_encoded.append(temp)\n",
    "    return onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "intellectual-intranet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man bites dog\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(processed_docs[1])\n",
    "get_onehot_vector(processed_docs[1]) #one hot representation for a text from our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "automatic-retention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_onehot_vector(\"man and dog are good\") \n",
    "#one hot representation for a random text, using the above vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "infectious-header",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_onehot_vector(\"man and man are good\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-rainbow",
   "metadata": {},
   "source": [
    "#### One-hot encoding with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "attempted-struggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "S1 = 'dog bites man'\n",
    "S2 = 'man bites dog'\n",
    "S3 = 'dog eats meat'\n",
    "S4 = 'man eats food'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "nuclear-tooth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data:  ['dog', 'bites', 'man', 'man', 'bites', 'dog', 'dog', 'eats', 'meat', 'man', 'eats', 'food']\n",
      "Label Encoded: [1 0 4 4 0 1 1 2 5 4 2 3]\n",
      "Onehot Encoded Matrix:\n",
      " [[1. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 1. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "data = [S1.split(), S2.split(), S3.split(), S4.split()]\n",
    "values = data[0]+data[1]+data[2]+data[3]\n",
    "print(\"The data: \",values)\n",
    "\n",
    "#Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print(\"Label Encoded:\",integer_encoded)\n",
    "\n",
    "#One-Hot Encoding\n",
    "onehot_encoder = OneHotEncoder()\n",
    "onehot_encoded = onehot_encoder.fit_transform(data).toarray()\n",
    "print(\"Onehot Encoded Matrix:\\n\",onehot_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-superior",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "featured-milton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog bites man', 'man bites dog', 'dog eats meat', 'man eats food']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [\"Dog bites man.\", \"Man bites dog.\", \"Dog eats meat.\", \"Man eats food.\"] #Same as the earlier notebook\n",
    "processed_docs = [doc.lower().replace(\".\",\"\") for doc in documents]\n",
    "processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "configured-immunology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our corpus:  ['dog bites man', 'man bites dog', 'dog eats meat', 'man eats food']\n",
      "Our vocabulary:  {'dog': 1, 'bites': 0, 'man': 4, 'eats': 2, 'meat': 5, 'food': 3}\n",
      "BoW representation for 'dog bites man':  [[1 1 0 0 1 0]]\n",
      "BoW representation for 'man bites dog:  [[1 1 0 0 1 0]]\n",
      "Bow representation for 'dog and dog are friends': [[0 2 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#look at the documents list\n",
    "print(\"Our corpus: \", processed_docs)\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "#Build a BOW representation for the corpus\n",
    "bow_rep = count_vect.fit_transform(processed_docs)\n",
    "\n",
    "#Look at the vocabulary mapping\n",
    "print(\"Our vocabulary: \", count_vect.vocabulary_)\n",
    "\n",
    "#see the BOW rep for first 2 documents\n",
    "print(\"BoW representation for 'dog bites man': \", bow_rep[0].toarray())\n",
    "print(\"BoW representation for 'man bites dog: \",bow_rep[1].toarray())\n",
    "\n",
    "#Get the representation using this vocabulary, for a new text\n",
    "temp = count_vect.transform([\"dog and dog are friends\"])\n",
    "print(\"Bow representation for 'dog and dog are friends':\", temp.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "institutional-pollution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bow representation for 'dog and dog are friends': [[0 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#BoW with binary vectors\n",
    "count_vect = CountVectorizer(binary=True)\n",
    "bow_rep_bin = count_vect.fit_transform(processed_docs)\n",
    "temp = count_vect.transform([\"dog and dog are friends\"])\n",
    "print(\"Bow representation for 'dog and dog are friends':\", temp.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-graph",
   "metadata": {},
   "source": [
    "### Bag of N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "indonesian-concert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog bites man', 'man bites dog', 'dog eats meat', 'man eats food']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#our corpus\n",
    "documents = [\"Dog bites man.\", \"Man bites dog.\", \"Dog eats meat.\", \"Man eats food.\"]\n",
    "\n",
    "processed_docs = [doc.lower().replace(\".\",\"\") for doc in documents]\n",
    "processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "spoken-phrase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our vocabulary:  {'dog': 3, 'bites': 0, 'man': 12, 'dog bites': 4, 'bites man': 2, 'dog bites man': 5, 'man bites': 13, 'bites dog': 1, 'man bites dog': 14, 'eats': 8, 'meat': 17, 'dog eats': 6, 'eats meat': 10, 'dog eats meat': 7, 'food': 11, 'man eats': 15, 'eats food': 9, 'man eats food': 16}\n",
      "BoW representation for 'dog bites man':  [[1 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0]]\n",
      "BoW representation for 'man bites dog:  [[1 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0]]\n",
      "Bow representation for 'dog and dog are friends': [[0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Ngram vectorization example with count vectorizer and uni, bi, trigrams\n",
    "count_vect = CountVectorizer(ngram_range=(1,3))\n",
    "\n",
    "#Build a BOW representation for the corpus\n",
    "bow_rep = count_vect.fit_transform(processed_docs)\n",
    "\n",
    "#Look at the vocabulary mapping\n",
    "print(\"Our vocabulary: \", count_vect.vocabulary_)\n",
    "\n",
    "#see the BOW rep for first 2 documents\n",
    "print(\"BoW representation for 'dog bites man': \", bow_rep[0].toarray())\n",
    "print(\"BoW representation for 'man bites dog: \",bow_rep[1].toarray())\n",
    "\n",
    "#Get the representation using this vocabulary, for a new text\n",
    "temp = count_vect.transform([\"dog and dog are friends\"])\n",
    "\n",
    "print(\"Bow representation for 'dog and dog are friends':\", temp.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-worst",
   "metadata": {},
   "source": [
    "### TD-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "compact-hearing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog bites man', 'man bites dog', 'dog eats meat', 'man eats food']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [\"Dog bites man.\", \"Man bites dog.\", \"Dog eats meat.\", \"Man eats food.\"]\n",
    "processed_docs = [doc.lower().replace(\".\",\"\") for doc in documents]\n",
    "processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "monetary-projection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF for all words in the vocabulary [1.51082562 1.22314355 1.51082562 1.91629073 1.22314355 1.91629073]\n",
      "----------\n",
      "All words in the vocabulary ['bites', 'dog', 'eats', 'food', 'man', 'meat']\n",
      "----------\n",
      "TFIDF representation for all documents in our corpus\n",
      " [[0.65782931 0.53256952 0.         0.         0.53256952 0.        ]\n",
      " [0.65782931 0.53256952 0.         0.         0.53256952 0.        ]\n",
      " [0.         0.44809973 0.55349232 0.         0.         0.70203482]\n",
      " [0.         0.         0.55349232 0.70203482 0.44809973 0.        ]]\n",
      "----------\n",
      "Tfidf representation for 'dog and man are friends':\n",
      " [[0.         0.70710678 0.         0.         0.70710678 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "bow_rep_tfidf = tfidf.fit_transform(processed_docs)\n",
    "\n",
    "#IDF for all words in the vocabulary\n",
    "print(\"IDF for all words in the vocabulary\",tfidf.idf_)\n",
    "print(\"-\"*10)\n",
    "#All words in the vocabulary.\n",
    "print(\"All words in the vocabulary\",tfidf.get_feature_names())\n",
    "print(\"-\"*10)\n",
    "\n",
    "#TFIDF representation for all documents in our corpus \n",
    "print(\"TFIDF representation for all documents in our corpus\\n\",bow_rep_tfidf.toarray()) \n",
    "print(\"-\"*10)\n",
    "\n",
    "temp = tfidf.transform([\"dog and man are friends\"])\n",
    "print(\"Tfidf representation for 'dog and man are friends':\\n\", temp.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-stupid",
   "metadata": {},
   "source": [
    "### Pre-trained word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "clinical-bernard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-08 09:38:30--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.27.86\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.27.86|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1647046227 (1.5G) [application/x-gzip]\n",
      "Saving to: ‘/tmp/input/GoogleNews-vectors-negative300.bin.gz’\n",
      "\n",
      "GoogleNews-vectors- 100%[===================>]   1.53G  1.02MB/s    in 24m 20s \n",
      "\n",
      "2021-03-08 10:02:50 (1.08 MB/s) - ‘/tmp/input/GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -P /tmp/input/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "imported-access",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings #This module ignores the various types of warnings generated\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "import os #This module provides a way of using operating system dependent functionality\n",
    "\n",
    "import psutil #This module helps in retrieving information on running processes and system resource utilization\n",
    "process = psutil.Process(os.getpid())\n",
    "from psutil import virtual_memory\n",
    "mem = virtual_memory()\n",
    "\n",
    "import time #This module is used to calculate the time  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "distributed-sound",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used in GB before Loading the Model: 0.13\n",
      "----------\n",
      "90.43 seconds taken to load\n",
      "----------\n",
      "Finished loading Word2Vec\n",
      "----------\n",
      "Memory used in GB after Loading the Model: 4.84\n",
      "----------\n",
      "Percentage increase in memory usage: 3671.56% \n",
      "----------\n",
      "Numver of words in vocablulary:  3000000\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "pretrainedpath = '/tmp/input/GoogleNews-vectors-negative300.bin.gz'\n",
    "\n",
    "#Load W2V model. This will take some time, but it is a one time effort! \n",
    "pre = process.memory_info().rss\n",
    "print(\"Memory used in GB before Loading the Model: %0.2f\"%float(pre/(10**9))) #Check memory usage before loading the model\n",
    "print('-'*10)\n",
    "\n",
    "start_time = time.time() #Start the timer\n",
    "ttl = mem.total #Toal memory available\n",
    "\n",
    "w2v_model = KeyedVectors.load_word2vec_format(pretrainedpath, binary=True) #load the model\n",
    "print(\"%0.2f seconds taken to load\"%float(time.time() - start_time)) #Calculate the total time elapsed since starting the timer\n",
    "print('-'*10)\n",
    "\n",
    "print('Finished loading Word2Vec')\n",
    "print('-'*10)\n",
    "\n",
    "post = process.memory_info().rss\n",
    "print(\"Memory used in GB after Loading the Model: {:.2f}\".format(float(post/(10**9)))) #Calculate the memory used after loading the model\n",
    "print('-'*10)\n",
    "\n",
    "print(\"Percentage increase in memory usage: {:.2f}% \".format(float((post/pre)*100))) #Percentage increase in memory after loading the model\n",
    "print('-'*10)\n",
    "\n",
    "print(\"Numver of words in vocablulary: \",len(w2v_model.vocab)) #Number of words in the vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "decent-documentary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gorgeous', 0.8353004455566406),\n",
       " ('lovely', 0.810693621635437),\n",
       " ('stunningly_beautiful', 0.7329413890838623),\n",
       " ('breathtakingly_beautiful', 0.7231341004371643),\n",
       " ('wonderful', 0.6854087114334106),\n",
       " ('fabulous', 0.6700063943862915),\n",
       " ('loveliest', 0.6612576246261597),\n",
       " ('prettiest', 0.6595001816749573),\n",
       " ('beatiful', 0.6593326330184937),\n",
       " ('magnificent', 0.6591402292251587)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let us examine the model by knowing what the most similar words are, for a given word!\n",
    "w2v_model.most_similar('beautiful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "greater-nickel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('montreal', 0.698411226272583),\n",
       " ('vancouver', 0.6587257385253906),\n",
       " ('nyc', 0.6248831748962402),\n",
       " ('alberta', 0.6179691553115845),\n",
       " ('boston', 0.611499547958374),\n",
       " ('calgary', 0.61032634973526),\n",
       " ('edmonton', 0.6100261211395264),\n",
       " ('canadian', 0.5944076776504517),\n",
       " ('chicago', 0.5911980271339417),\n",
       " ('springfield', 0.5888351202011108)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let us try with another word! \n",
    "w2v_model.most_similar('toronto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sustained-bobby",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What is the vector representation for a word? \n",
    "w2v_model['computer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "comfortable-mustang",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'practicalnlp' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-354849ef77a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#What if I am looking for a word that is not in this vocabulary?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mw2v_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'practicalnlp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/marcos/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marcos/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marcos/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'practicalnlp' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "#What if I am looking for a word that is not in this vocabulary?\n",
    "w2v_model['practicalnlp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-wayne",
   "metadata": {},
   "source": [
    "### Document Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "separated-democracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_sm==2.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz (12.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.0 MB 926 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy>=2.2.0 in /home/marcos/anaconda3/lib/python3.7/site-packages (from en_core_web_sm==2.2.0) (2.2.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/marcos/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/marcos/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (3.0.2)\n",
      "Requirement already satisfied: thinc<7.2.0,>=7.1.1 in /home/marcos/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (7.1.1)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/marcos/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (0.4.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /home/marcos/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (1.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /home/marcos/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (0.8.1)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /home/marcos/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (0.9.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/marcos/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (2.21.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/marcos/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (2.0.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/marcos/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.0->en_core_web_sm==2.2.0) (1.20.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/marcos/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/marcos/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0) (1.24.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/marcos/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/marcos/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en_core_web_sm==2.2.0) (3.0.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /home/marcos/anaconda3/lib/python3.7/site-packages (from thinc<7.2.0,>=7.1.1->spacy>=2.2.0->en_core_web_sm==2.2.0) (4.56.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# downloading en_core_web_sm, assuming spacy is already installed\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "antique-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import spacy and load the model\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\") #here nlp object refers to the 'en_core_web_sm' language model instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "freelance-hughes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document After Pre-Processing: ['dog bites man', 'man bites dog', 'dog eats meat', 'man eats food']\n",
      "------------------------------\n",
      "Average Vector of 'dog bites man'\n",
      " [-7.98439980e-01  5.03663123e-01 -2.41333127e-01 -6.64204419e-01\n",
      "  5.01806140e-01 -6.74253047e-01 -1.00533640e+00  1.97439814e+00\n",
      "  8.57585609e-01 -2.28153682e+00  2.43162110e-01  4.73274350e-01\n",
      "  1.80249548e+00  4.70105022e-01 -1.42042732e+00 -2.20901608e+00\n",
      "  5.37633896e-05 -1.98789418e+00 -1.47917545e+00  3.49637151e-01\n",
      "  3.83039325e-01 -5.82689881e-01  1.85989869e+00  2.99053931e+00\n",
      "  6.42488956e-01 -8.62058342e-01 -4.78679568e-01  3.55151184e-02\n",
      " -2.50659078e-01  1.39876425e+00 -1.15447450e+00 -2.08678555e+00\n",
      " -1.59011745e+00 -6.11391962e-01  1.15350544e+00 -5.72167456e-01\n",
      " -1.08172190e+00 -8.36121857e-01 -5.66980064e-01  1.77348197e-01\n",
      " -3.68608050e-02  1.15231264e+00 -1.20345271e+00  3.03640437e+00\n",
      "  9.61066544e-01 -2.99080682e+00  1.09146990e-01  1.91626266e-01\n",
      " -1.35101545e+00 -2.54559803e+00 -2.77168536e+00 -1.13090420e+00\n",
      " -8.60304356e-01  2.51131535e+00  5.47873199e-01 -4.58268404e-01\n",
      "  4.81076837e-02  6.21307313e-01  2.50590444e+00  7.13617623e-01\n",
      " -1.53748655e+00  2.29871058e+00 -6.50613070e-01  1.02046835e+00\n",
      "  7.97305346e-01  4.88608688e-01 -1.10009265e+00  1.22871244e+00\n",
      " -1.66750804e-01 -1.08307838e+00 -3.73702459e-02 -2.11233211e+00\n",
      " -9.29002464e-01 -1.11062385e-01  1.25730723e-01 -6.94367886e-01\n",
      "  1.16395938e+00  1.38275254e+00  6.79315567e-01 -6.71766102e-01\n",
      " -1.68262756e+00  1.62626016e+00 -6.08399034e-01  1.84714639e+00\n",
      "  2.41249633e+00 -8.08819354e-01  5.14104307e-01  2.10758042e+00\n",
      "  2.18226528e+00  6.68389976e-01 -2.07666799e-01  2.24301577e-01\n",
      "  2.48108196e+00 -2.59068990e+00  4.83865023e-01  7.77615726e-01]\n",
      "\n",
      "dog [-3.3867488e+00  1.8035629e+00 -1.4304888e+00  1.1607424e+00\n",
      "  1.8462464e-01 -1.5591600e+00 -2.1822851e+00  2.2744513e+00\n",
      "  2.1251135e+00 -1.6137670e+00 -1.0155161e-01  2.9701507e-01\n",
      "  8.3569223e-01  1.9860228e+00  3.2478017e-01 -3.4556108e+00\n",
      "  5.8896720e-01 -3.9743829e+00 -2.7407756e+00  6.2403077e-01\n",
      "  3.3552611e-01  7.8374147e-04  2.5513959e+00  4.1839266e+00\n",
      "  9.1306502e-01  2.1259931e-01 -2.6703517e+00  3.3345976e+00\n",
      " -1.7864487e+00 -2.0015783e+00 -2.3100848e+00 -1.8271587e+00\n",
      " -7.1444350e-01 -4.1570210e-01  1.3059633e+00  3.1065738e-01\n",
      " -1.4057486e+00 -2.7547033e+00  6.5965995e-02 -8.9035082e-01\n",
      "  3.0579549e-01  6.4937639e-01  6.9317102e-02  5.0726838e+00\n",
      "  6.5046704e-01 -4.1679392e+00  1.2107239e+00 -1.7516720e-01\n",
      " -2.9240553e+00 -2.3529150e+00 -1.6854944e+00 -1.2624822e+00\n",
      " -1.2875682e-01  2.1831217e+00 -2.3979366e+00  4.8093855e-01\n",
      " -7.9299659e-01  3.0172977e+00  3.8270714e+00 -5.3632641e-01\n",
      " -2.2737970e+00  8.9579320e-01 -2.3856540e+00  4.1307583e-01\n",
      "  2.3342893e+00 -1.4667726e+00  9.4786763e-01  1.0484588e+00\n",
      " -9.5108938e-01 -1.7331651e+00 -3.0716085e-01 -1.9492507e-02\n",
      " -1.7554631e+00  3.5773408e-01  7.3857981e-01 -3.8554174e-01\n",
      "  1.9180570e+00  1.6533080e+00  2.5168819e+00  4.4299671e-01\n",
      " -5.8678538e-01  1.5103650e+00 -2.4096885e+00  2.0371017e+00\n",
      " -3.9033014e-01  2.7654943e-01 -1.4231827e+00  3.3701487e+00\n",
      "  3.1899028e+00  5.9775710e-01 -9.3297589e-01  3.4266651e-01\n",
      "  3.2094271e+00 -4.3642931e+00  1.0161214e+00  3.1504567e+00]\n",
      "\n",
      "bites [ 0.952706    0.4174019  -0.00723654 -0.3156501   0.44675738 -1.3273654\n",
      " -1.1072183   0.9968554  -2.5440688  -2.1787424   2.418      -0.10886225\n",
      "  2.8335438  -0.45028234 -2.4200954  -2.672755   -1.9165353  -2.3686295\n",
      " -0.8996263   1.2949188  -0.6821388   0.28707033  2.8783436   3.1369693\n",
      " -1.4726965   0.22581819  2.372287   -3.1934304   2.3565223   3.4457483\n",
      "  0.13308913 -0.82530236 -2.124344    1.318342    0.930156   -0.77561784\n",
      " -0.3074538  -0.41822016 -0.39668804  1.4216204  -1.2779633  -0.9703841\n",
      " -1.9024      5.494334    3.2871232  -0.8674768  -1.9990568  -0.76796937\n",
      "  0.37739003 -3.2506645  -2.7419298  -1.779861    0.59473175  3.8411684\n",
      "  3.8161163  -2.3402236  -0.20021892 -2.0484078   0.12120783  1.113875\n",
      " -4.729205    3.8258078   0.02963591 -0.69417536 -1.0354073   0.9910511\n",
      " -1.9890118   1.0359297   1.0961099  -2.648275   -0.3156364  -4.971911\n",
      " -1.0216497  -1.1684233  -0.75273263 -1.0395445   0.08647668  2.2222114\n",
      " -0.49790215 -1.2351356  -3.5355077   0.07711899  2.089424    2.8815966\n",
      "  4.779628    0.04313564  2.5134082   2.7830472   1.996296    0.35341084\n",
      " -1.6243103   1.856748    3.591835   -0.05668166 -2.1950345  -2.7504077 ]\n",
      "\n",
      "man [ 3.8722932e-02 -7.0997554e-01  7.1372592e-01 -2.8377056e+00\n",
      "  8.7403643e-01  8.6376625e-01  2.7349406e-01  2.6518879e+00\n",
      "  2.9917121e+00 -3.0521009e+00 -1.5869621e+00  1.2316703e+00\n",
      "  1.7382505e+00 -1.2542546e-01 -2.1659670e+00 -4.9868292e-01\n",
      "  1.3277293e+00  3.7932971e-01 -7.9712439e-01 -8.7003815e-01\n",
      "  1.4957306e+00 -2.0359237e+00  1.4995657e-01  1.6507218e+00\n",
      "  2.4870985e+00 -3.0245924e+00 -1.1379740e+00 -3.4621805e-02\n",
      " -1.3220508e+00  2.7521226e+00 -1.2864277e+00 -3.6078954e+00\n",
      " -1.9315650e+00 -2.7368157e+00  1.2243972e+00 -1.2515420e+00\n",
      " -1.5319633e+00  6.6455793e-01 -1.3702180e+00  7.7503175e-04\n",
      "  8.6158538e-01  3.7779455e+00 -1.7772751e+00 -1.4578052e+00\n",
      " -1.0543905e+00 -3.9370046e+00  1.1157739e+00  1.5180154e+00\n",
      " -1.5063813e+00 -2.0332148e+00 -3.8876309e+00 -3.5036945e-01\n",
      " -3.0468879e+00  1.5096562e+00  2.2543988e-01  4.8447984e-01\n",
      "  1.1375386e+00  8.9503187e-01  3.5694344e+00  1.5633044e+00\n",
      "  2.3905425e+00  2.1745307e+00  4.0417892e-01  3.3425045e+00\n",
      "  1.0930340e+00  1.9415475e+00 -2.2591338e+00  1.6017489e+00\n",
      " -6.4527291e-01  1.1322050e+00  5.1068652e-01 -1.3455925e+00\n",
      " -9.8943710e-03  4.7750205e-01  3.9134499e-01 -6.5801728e-01\n",
      "  1.4873443e+00  2.7273864e-01  1.8966883e-02 -1.2231597e+00\n",
      " -9.2558938e-01  3.2912962e+00 -1.5049325e+00  6.2274051e-01\n",
      "  2.8481910e+00 -2.7461431e+00  4.5208752e-01  1.6954497e-01\n",
      "  1.3605974e+00  1.0540020e+00  1.9342859e+00 -1.5265098e+00\n",
      "  6.4198411e-01 -3.3510947e+00  2.6305082e+00  1.9327981e+00]\n",
      "------------------------------\n",
      "Average Vector of 'man bites dog'\n",
      " [-0.33060998  0.41962197 -0.58338857 -1.1181337  -0.04044279 -0.5173791\n",
      " -1.7297405   0.9179871   0.54943115 -1.5833873   0.05188833  0.51039594\n",
      "  0.50392026  0.62556666 -0.691024   -2.1559677   0.2666646  -0.87901497\n",
      " -1.6145334   0.3501416   0.65292907 -0.10149511  2.0586627   2.5174305\n",
      "  0.60579926 -0.14649515 -1.3118154   0.0896666  -1.3439041   0.15964037\n",
      " -1.247058   -1.2557018  -1.2057441  -0.97791433  2.6350613   0.28114715\n",
      " -0.9449087  -0.758589   -0.37210336  0.40749776 -0.68046093  1.6004919\n",
      " -0.916337    2.9242277   1.2211004  -2.5344841   0.16904962  0.6139651\n",
      " -1.6437517  -2.6306932  -3.0446246  -1.0045812  -0.3790582   1.726727\n",
      "  0.96820337 -0.17736991  0.35057974  0.42807373  1.8285643   0.22092648\n",
      " -1.0542337   2.4518633  -0.8623347   0.8020784   1.2830391   0.5653097\n",
      " -0.18893261 -0.29141384 -0.48416543 -0.38077274 -0.31937817 -2.2490253\n",
      " -1.0252923  -0.15960662 -0.4095513  -0.54347235  0.66789037  0.49896535\n",
      "  0.70303804 -0.9383364  -1.6992809   2.1431363  -0.6948783   1.5588322\n",
      "  2.231185   -0.07041029  0.7948875   1.9996666   1.945403    1.3710178\n",
      " -0.45645323  1.0712653   2.7167823  -1.8694252  -0.266503    0.29618844]\n",
      "\n",
      "man [-1.7537284e+00  1.4124393e-02 -8.8561916e-01  1.9792345e-01\n",
      " -2.2783357e-01 -4.9152425e-01 -5.8483648e-01  2.5408382e+00\n",
      "  3.1235437e+00 -3.7344441e+00 -2.6525247e+00  6.0853553e-01\n",
      "  3.6900908e-02  3.6589733e-01  4.2197680e-01 -2.6871891e+00\n",
      " -2.1674037e-03 -1.1728196e+00 -1.6147935e+00 -1.4039785e+00\n",
      "  1.5696404e+00 -2.9078455e+00  2.1382816e+00  1.4216640e+00\n",
      " -3.4613347e-01 -1.9598565e-01 -2.5815735e+00  9.5708680e-01\n",
      " -3.9497824e+00 -1.9455122e+00 -2.0659380e+00 -1.0128717e+00\n",
      " -2.7918369e-01 -2.1344733e+00  1.2954482e+00 -1.0406435e+00\n",
      " -1.7175109e+00 -4.8147035e-01  2.1052577e-01  1.0468411e+00\n",
      " -2.8608912e-01 -1.6694462e-01 -1.1801021e+00  2.7962639e+00\n",
      "  1.0944890e+00 -3.1687381e+00 -1.9185661e-01  7.2792256e-01\n",
      " -2.5401618e+00 -2.2359338e+00 -2.4261391e+00 -1.7858067e+00\n",
      "  2.2963541e+00  1.2038254e+00 -1.6114476e-01  2.6389723e+00\n",
      "  9.5340538e-01  1.9575164e+00  2.2810595e+00  1.6878005e+00\n",
      "  1.0897297e+00  2.0375204e+00 -1.6683571e+00  4.3062243e+00\n",
      "  1.6520913e+00 -1.5727143e+00 -2.9388762e+00  4.7688609e-01\n",
      "  1.4082553e+00 -2.2476697e+00 -2.0080018e+00  2.2129297e+00\n",
      " -2.9147363e+00  1.8858685e+00 -5.1167440e-01  2.3870701e-01\n",
      "  5.9445310e-01  6.8363488e-01  1.9849962e-01  2.4165881e-01\n",
      " -2.9140258e-01  4.5070829e+00 -3.8654810e-01  1.7324674e+00\n",
      "  2.9815979e+00 -5.5088699e-01  7.6170212e-01  8.3168775e-01\n",
      "  3.2928407e+00 -8.0615604e-01  7.8403890e-01  9.1698492e-01\n",
      "  1.1801968e+00 -3.8339019e+00  4.5851028e-01  3.2262430e+00]\n",
      "\n",
      "bites [ 1.6476912   0.90402925 -0.1579172  -0.05925989  0.5362887  -0.5468755\n",
      " -2.773378   -0.03928131 -3.256016   -0.8554877   2.8535984  -1.3029752\n",
      "  0.3388983   0.21489367 -2.3387806  -3.4259505  -1.825666   -0.5010501\n",
      " -1.1931604   0.7266425  -1.2963166   1.1981239   3.1663527   2.5034544\n",
      " -1.1494634   0.9889748   1.239948   -2.8698924   0.55927634  2.931019\n",
      " -1.0485914  -0.02433711 -1.4885334   1.3441767   4.341674    1.1366882\n",
      "  0.56277823 -0.5698276   0.35212058  1.0479883  -2.0571988  -0.09484756\n",
      " -0.889131    4.513942    2.8478243  -0.76432705 -1.6739906  -1.2572289\n",
      " -2.0274837  -3.9101079  -3.6063783  -0.5272155   0.6408493   2.7651758\n",
      "  4.797786   -1.9936771   0.1239053  -3.357738   -0.91297376  0.2513765\n",
      " -3.5359309   4.2474117  -0.24943209 -1.7675997   0.02246833  1.9602387\n",
      "  0.90702486 -1.1506727  -0.23250148 -1.5851637   0.10897446 -5.050424\n",
      " -1.4355237  -0.5210272  -0.94293576 -0.17194325 -0.1077463  -0.0730496\n",
      "  0.35786596 -0.8040464  -4.1540875  -0.16322678  1.2836795   1.9210427\n",
      "  4.082821    1.5549215   2.448298    2.1332717   1.9882799   0.9339794\n",
      " -0.8701362   3.1871657   3.9265547   1.4855087  -3.5961545  -2.2676318 ]\n",
      "\n",
      "dog [-0.8857928   0.34071228 -0.7066293  -3.4930644  -0.4297835  -0.51373756\n",
      " -1.8310072   0.25240436  1.7807658  -0.16022985 -0.04540867  2.2256274\n",
      "  1.1359615   1.295909   -0.15626824 -0.3547637   2.6278272  -0.96317506\n",
      " -2.0356462   1.7277608   1.6854634   1.4052362   0.8713535   3.6271737\n",
      "  3.3129947  -1.2324746  -2.5938206   2.1818054  -0.6412065  -0.5065858\n",
      " -0.62664497 -2.7298965  -1.8495154  -2.1434462   2.2680616   0.7473967\n",
      " -1.6799934  -1.2244692  -1.6789564  -0.87233627  0.3019051   5.0632677\n",
      " -0.67977774  1.4624776  -0.27901185 -3.6703875   2.372996    2.3712015\n",
      " -0.36361003 -1.7460375  -3.1013563  -0.7007215  -4.074378    1.2111796\n",
      " -1.7320313  -1.1774049  -0.0255715   2.6844428   4.117607   -1.2763976\n",
      " -0.71649957  1.0706576  -0.669215   -0.13238955  2.1745577   1.3084047\n",
      "  1.4650534  -0.20045495 -2.6282501   2.690515    0.9408928  -3.9095817\n",
      "  1.274383   -1.8436612   0.22595617 -1.6971807   1.5169643   0.8863108\n",
      "  1.5527487  -2.2526214  -0.6523527   2.0855527  -2.9817662   1.0229862\n",
      " -0.37086397 -1.2152654  -0.8253377   3.03404     0.555088    3.9852297\n",
      " -1.2832625  -0.89035463  3.043595   -3.259882    2.3381352  -0.07004589]\n",
      "------------------------------\n",
      "Average Vector of 'dog eats meat'\n",
      " [-0.25775456  0.141438    0.3886855  -2.3011904   0.39842734 -0.6081791\n",
      " -1.2250029  -1.7801656   0.4469219  -0.15644874  0.03971388  0.69238013\n",
      "  0.19213416  1.5824732  -0.09573364 -3.1317008   1.601298   -3.2979982\n",
      " -1.4682912   0.46852145  1.6278473  -0.12382134  2.8501005   2.1972485\n",
      "  2.8134995  -0.7971103  -1.0741369   0.11260433 -1.6624657   0.73300314\n",
      " -1.8149347  -2.3604772   0.3539401   0.13100243  1.9395076  -0.26045322\n",
      " -0.8804147   0.726214   -1.1140556  -0.31497416 -0.86101097  0.3294011\n",
      " -0.25652784  1.6677643   0.81275535 -3.7262554   1.2683749  -0.03228636\n",
      " -0.8491927  -2.0679157  -1.6568462  -0.02691636  0.9351656   0.6736434\n",
      " -0.421514    0.18567272 -0.55376035  1.6299801   2.9597223  -0.24303782\n",
      " -3.1609735   0.8126462  -0.18958615  0.10197719  2.0899267  -0.8066244\n",
      " -0.2388109   0.631889   -0.8147226  -0.6962773   1.0101398  -3.197152\n",
      "  0.42598006 -0.5602657   0.79066664 -1.4255239   0.5077756   1.469604\n",
      "  1.9884523  -2.5171428   0.45194528  0.6530646   0.47578564  2.4581506\n",
      "  1.2491989   0.22095072 -0.8140383   2.9540513   1.8147482   1.7825514\n",
      " -0.56847924  0.11979002  4.047025   -3.5193489   0.6949702  -0.5999457 ]\n",
      "\n",
      "dog [-3.0915658   0.46042415 -2.7442706  -0.19290999 -0.12077338 -0.66540706\n",
      " -0.7572613  -0.1838975   1.465822   -1.5650203  -0.7027039   0.21189788\n",
      "  0.23603112  1.4771649   0.92864347 -2.6694262   1.2249625  -4.8111997\n",
      " -1.844302    0.05865675  1.430345   -0.90132093  2.758955    4.331203\n",
      "  2.849482    0.36691794 -2.0395782   2.7671158  -2.960103   -1.9542134\n",
      " -1.904417   -2.5558746  -0.04852474 -0.55458796  2.8964536   0.46486366\n",
      "  0.34457117 -2.0944855  -0.26235914 -0.35082132  0.19873816  0.70890784\n",
      " -1.1431341   3.5512564   1.3838598  -5.743266    0.46248147  0.9128883\n",
      " -2.1766129  -2.2812917  -2.0383441  -0.32769376  1.0582175   3.1455073\n",
      " -1.3094703   0.7323883  -3.170281    2.8859713   3.8992615  -0.6270603\n",
      " -3.1440797   0.48367906 -1.5694027   0.44087583  3.1839745  -1.9028109\n",
      "  1.0008215  -0.20376027 -0.91459817 -1.5217931   0.93096876 -0.29734725\n",
      " -1.8705771   0.97129726  0.58270776 -0.4350645   1.3968809   2.489727\n",
      "  2.440142   -2.1539316  -0.33468878  3.1936142  -2.7710044   0.75310636\n",
      "  0.9347232   0.7192168  -1.7043836   4.603369    3.3470898   1.1025712\n",
      " -1.2034445  -0.17290717  3.493872   -3.6577373   0.9099171   0.8583978 ]\n",
      "\n",
      "eats [ 3.122393    0.21281797  1.5146528  -2.174739   -1.1231327  -1.8682208\n",
      " -3.9796581  -3.022224   -0.53754306  0.61993426  1.0618345  -0.71134216\n",
      "  0.5674193   0.7052727   0.5351625  -4.0840816   1.3203057  -3.8008103\n",
      " -1.1780038   1.295818   -0.58442605 -1.3840753   3.6912746   0.08091328\n",
      "  3.8972058  -1.6223288  -0.01402895 -2.7798772   0.39257526  2.516714\n",
      " -2.3907037  -1.580251   -2.4928246   3.5355413   3.148695   -0.9627291\n",
      "  0.48597002  1.2350404  -1.5704215   0.1964103  -1.6887034  -0.8526693\n",
      " -0.27983874 -0.35893798  2.3678367  -1.6816065   1.6980008  -1.1324317\n",
      "  0.61934125 -4.0090737  -1.7537403   1.1407039   2.2651787   0.36754704\n",
      "  2.4007804  -0.67063147  2.4199846  -0.7982217   0.57018465  1.9870195\n",
      " -6.3892827   2.113063    0.34839487  0.49313325  3.7369204  -1.0212593\n",
      " -0.41294953  1.1486957  -1.7037911   1.3021995   0.62492424 -4.788063\n",
      "  1.1457952  -2.2893925   1.792823   -1.8613187  -0.32493424 -0.6167244\n",
      "  0.87917864 -2.6377668   1.1649228  -0.33624792  2.5851436   4.4532623\n",
      "  2.2645712   1.5652391   0.77069026  2.839027   -0.28478077  0.70413333\n",
      " -0.521905    1.0268145   7.844699   -2.6890519  -1.5726371  -2.4473276 ]\n",
      "\n",
      "meat [-8.0409074e-01 -2.4892808e-01  2.3956742e+00 -4.5359221e+00\n",
      "  2.4391880e+00  7.0909071e-01  1.0619106e+00 -2.1343751e+00\n",
      "  4.1248673e-01  4.7573984e-01 -2.3998892e-01  2.5765846e+00\n",
      " -2.2704792e-01  2.5649822e+00 -1.7510068e+00 -2.6415946e+00\n",
      "  2.2586257e+00 -1.2819847e+00 -1.3825673e+00  5.1089540e-02\n",
      "  4.0376229e+00  1.9139321e+00  2.1000717e+00  2.1796293e+00\n",
      "  1.6938107e+00 -1.1359202e+00 -1.1688032e+00  3.5057434e-01\n",
      " -2.4198694e+00  1.6365088e+00 -1.1496837e+00 -2.9453063e+00\n",
      "  3.6031697e+00 -2.5879459e+00 -2.2662598e-01 -2.8349420e-01\n",
      " -3.4717853e+00  3.0380871e+00 -1.5093862e+00 -7.9051149e-01\n",
      " -1.0930676e+00  1.1319648e+00  6.5338939e-01  1.8109748e+00\n",
      " -1.3134305e+00 -3.7538943e+00  1.6446426e+00  1.2268439e-01\n",
      " -9.9030650e-01  8.6617827e-02 -1.1784540e+00 -8.9375925e-01\n",
      " -5.1789951e-01 -1.4921241e+00 -2.3558521e+00  4.9526131e-01\n",
      " -9.1098481e-01  2.8021905e+00  4.4097204e+00 -2.0890727e+00\n",
      "  5.0441414e-02 -1.5880346e-01  6.5224940e-01 -6.2807751e-01\n",
      " -6.5111446e-01  5.0419706e-01 -1.3043046e+00  9.5073152e-01\n",
      "  1.7422152e-01 -1.8692381e+00  1.4745264e+00 -4.5060449e+00\n",
      "  2.0027220e+00 -3.6270189e-01 -3.5307109e-03 -1.9801886e+00\n",
      "  4.5138031e-01  2.5358093e+00  2.6460359e+00 -2.7597299e+00\n",
      "  5.2560174e-01 -8.9817250e-01  1.6132178e+00  2.1680837e+00\n",
      "  5.4830247e-01 -1.6216036e+00 -1.5084214e+00  1.4197576e+00\n",
      "  2.3819351e+00  3.5409501e+00  1.9911617e-02 -4.9453723e-01\n",
      "  8.0250466e-01 -4.2112570e+00  2.7476306e+00 -2.1090728e-01]\n",
      "------------------------------\n",
      "Average Vector of 'man eats food'\n",
      " [-6.2641501e-02  1.6550209e-01  7.2483510e-01 -2.3990324e+00\n",
      " -1.2923191e+00  1.5049593e-01 -1.3389077e+00 -6.8560076e-01\n",
      "  1.7088000e-01 -4.7368118e-01 -7.9583168e-01  2.2869706e-02\n",
      " -5.4554993e-01  1.5717837e+00  1.6848080e-01 -2.8153486e+00\n",
      "  1.8897736e-01 -6.4816493e-01 -1.0276351e+00  1.6349463e-01\n",
      "  1.0070695e+00 -1.7496711e+00  3.7437947e+00  1.9154202e+00\n",
      "  3.1060874e+00 -8.5429007e-01  4.1173545e-01 -2.2929199e-01\n",
      " -1.5585483e+00  7.3094893e-01 -1.3064438e+00 -1.7749701e+00\n",
      "  3.6838064e-01 -3.7047514e-01  2.4889526e+00 -9.0347242e-01\n",
      " -8.4621590e-01  2.1657794e+00 -1.0542258e+00  1.5291770e-01\n",
      " -1.1338124e+00  1.1448165e-03 -1.6713090e+00  6.5291125e-01\n",
      "  1.2015868e+00 -2.8492877e+00  1.8902591e+00  4.5579156e-01\n",
      " -1.8045739e+00 -2.6704423e+00 -1.7357625e+00 -3.0083576e-02\n",
      "  2.1822844e+00 -1.1747569e+00 -1.6687075e-02  1.2130929e+00\n",
      "  5.0406892e-02  8.8442564e-01  2.2557547e+00 -8.1279498e-01\n",
      " -1.4738326e+00  2.4423497e+00 -7.8752589e-01  1.5974799e+00\n",
      "  1.8985695e+00 -5.2918285e-01 -1.1281823e+00 -1.1661421e+00\n",
      "  8.1491703e-01 -1.3911764e-02 -4.7877064e-01 -1.9024004e+00\n",
      " -9.5008880e-01 -6.1224084e-02  6.4022642e-01 -4.5703030e-01\n",
      "  1.3365577e+00  9.9214338e-02  7.2648066e-01 -1.5306616e+00\n",
      " -5.0515771e-02  1.3769516e+00  6.9222432e-01  9.8307055e-01\n",
      "  1.5422493e+00 -1.1323761e+00 -4.3441129e-01  1.7774113e+00\n",
      "  4.1167417e-01  1.7774175e+00  1.3798529e+00  8.9496130e-01\n",
      "  2.3122411e+00 -2.2064831e+00  6.6513699e-01  6.1683124e-01]\n",
      "\n",
      "man [-1.6181862e+00 -6.1802864e-01 -5.4451597e-01 -1.1168638e+00\n",
      " -1.0861882e+00  3.0542558e-01 -5.9962988e-02  1.2806385e+00\n",
      "  3.0993180e+00 -4.1852121e+00 -2.9883027e+00 -2.8986973e-01\n",
      " -4.5494467e-01  7.0036834e-01  1.1111796e+00 -2.4173284e+00\n",
      "  4.0493745e-01 -1.4931769e+00 -2.6413530e-01 -3.0940585e+00\n",
      "  2.3103099e+00 -3.8986475e+00  2.4347415e+00  1.3001406e+00\n",
      "  1.2790886e+00 -1.5361956e-01 -1.3112202e+00  6.7946470e-01\n",
      " -4.5287352e+00 -8.1594491e-01 -1.3288213e+00 -2.2847846e+00\n",
      "  7.3104429e-01 -1.3010974e+00  3.3029213e+00 -7.3450255e-01\n",
      "  9.7102642e-02 -1.3800398e-01 -1.6665393e-01  9.9562246e-01\n",
      " -3.4005988e-01 -6.8294752e-01 -2.7406549e+00  1.4637878e+00\n",
      "  1.1866978e+00 -4.7239466e+00 -1.1998718e+00  2.4329190e+00\n",
      " -1.8293839e+00 -2.1544096e+00 -2.4920919e+00 -4.7670016e-01\n",
      "  3.3610094e+00  1.9399402e+00 -5.1932061e-01  2.8182371e+00\n",
      " -1.3523853e+00  1.1287093e+00  2.2239583e+00  7.5897288e-01\n",
      "  9.6740258e-01  2.5059500e+00 -3.8718432e-01  4.9379911e+00\n",
      "  2.6680641e+00 -1.6366506e+00 -2.6480837e+00 -5.3869218e-02\n",
      "  7.1517771e-01 -2.0015106e+00 -1.1697147e+00  1.4447727e+00\n",
      " -3.0644534e+00  2.3579779e+00 -1.7298650e+00  5.3691089e-01\n",
      "  6.4654261e-01  1.0437571e+00 -3.5542011e-02 -2.1130402e+00\n",
      " -3.4486055e-03  5.1111808e+00 -5.9086609e-01  4.3536901e-01\n",
      "  3.7277269e+00 -9.8416650e-01  1.0802697e+00  1.8864892e+00\n",
      "  2.7703240e+00 -4.0070355e-01  1.1436663e+00 -2.0393550e-02\n",
      "  9.6201420e-01 -2.5123725e+00  1.3504237e-01  2.0021994e+00]\n",
      "\n",
      "eats [ 2.8377914   0.7536158   2.4175396  -1.3596793  -1.0088787  -1.6854589\n",
      " -3.93406    -2.6234531  -2.3779314   1.9144838   0.31106943 -0.8481962\n",
      " -0.8434973   2.1266232   0.02747963 -3.6265988  -0.895204    0.5400264\n",
      "  0.7737246   1.6977082  -1.0109928   0.54899156  4.7052765   0.05936164\n",
      "  4.396554   -0.71041226  0.5733397  -3.16463     0.10837775  1.5904877\n",
      " -1.3865715  -0.7773327  -2.6384206   2.8708425   4.080837   -0.03767955\n",
      "  0.09259939  0.42026943 -1.7123893   0.22099397 -3.0881896   0.2961185\n",
      " -0.5053294  -0.8692287   1.7184833  -1.0545074   1.7551942  -1.3220956\n",
      " -3.830607   -4.77948    -2.5287042   1.518615    3.5644188  -2.998044\n",
      "  2.0528965  -1.0362444   3.2241666  -0.1605426  -1.1046994   1.287516\n",
      " -5.5037513   3.7499557  -0.09206611  0.4653839   3.1527493  -1.081955\n",
      " -0.13866067 -0.3682684  -0.51646733  0.5523174  -0.6380356  -5.8986554\n",
      "  0.7990869  -1.824313    1.817178   -0.6251913   1.2888656  -1.7285522\n",
      "  1.109453   -2.9825969   0.09847376 -0.89147496  3.5490737   2.2514906\n",
      "  1.7691131   1.7017688   0.21154493  3.349972   -1.1817479   0.29902008\n",
      "  1.3396723   3.0096004   6.422019   -1.9492366  -1.4001783  -0.7991104 ]\n",
      "\n",
      "food [-1.4075297   0.36091912  0.3014816  -4.720554   -1.7818902   1.831521\n",
      " -0.02270028 -0.7139876  -0.20874667  0.84968483  0.28973806  1.206675\n",
      " -0.33820784  1.8883597  -0.63321686 -2.4021184   1.0571986  -0.99134433\n",
      " -3.5924947   1.8868341   1.721891   -1.8993572   4.091366    4.3867583\n",
      "  3.6426194  -1.6988385   1.9730868   1.7972891  -0.25528768  1.4183041\n",
      " -1.2039387  -2.2627926   3.0125182  -2.6811705   0.08309968 -1.9382352\n",
      " -2.7283497   6.2150726  -1.2836338  -0.7578633   0.0268122   0.39026347\n",
      " -1.7679427   1.3641747   0.6995796  -2.7694094   5.1154547   0.2565513\n",
      "  0.24626908 -1.0774376  -0.18649149 -1.1321656  -0.3785755  -2.466167\n",
      " -1.5836371   1.8572863  -1.7205607   1.6851101   5.6480055  -4.484874\n",
      "  0.11485085  1.0711433  -1.8833272  -0.61093515 -0.12510467  1.131057\n",
      " -0.59780264 -3.076289    2.2460406   1.407458    0.37143826 -1.2533181\n",
      " -0.58489984 -0.7173371   1.8333663  -1.2828106   2.0742648   0.98243815\n",
      "  1.105531    0.50365245 -0.24657246 -0.08885089 -0.8815347   0.26235205\n",
      " -0.8700919  -4.1147304  -2.5950484   0.09577283 -0.3535536   5.433936\n",
      "  1.6562204  -0.30432296 -0.44731003 -2.1578403   3.260547    0.6474046 ]\n"
     ]
    }
   ],
   "source": [
    "#Assume each sentence in documents corresponds to a separate document.\n",
    "documents = [\"Dog bites man.\", \"Man bites dog.\", \"Dog eats meat.\", \"Man eats food.\"]\n",
    "processed_docs = [doc.lower().replace(\".\",\"\") for doc in documents]\n",
    "processed_docs\n",
    "\n",
    "print(\"Document After Pre-Processing:\",processed_docs)\n",
    "\n",
    "\n",
    "#Iterate over each document and initiate an nlp instance.\n",
    "for doc in processed_docs:\n",
    "    doc_nlp = nlp(doc) #creating a spacy \"Doc\" object which is a container for accessing linguistic annotations. \n",
    "    \n",
    "    print(\"-\"*30)\n",
    "    print(\"Average Vector of '{}'\\n\".format(doc),doc_nlp.vector)#this gives the average vector of each document\n",
    "    for token in doc_nlp:\n",
    "        print()\n",
    "        print(token.text,token.vector)#this gives the text of each word in the doc and their respective vectors.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-premises",
   "metadata": {},
   "source": [
    "### Doc3Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "recovered-loading",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/marcos/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "guilty-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\"dog bites man\",\n",
    "        \"man bites dog\",\n",
    "        \"dog eats meat\",\n",
    "        \"man eats food\"]\n",
    "\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(word.lower()), tags=[str(i)]) for i, word in enumerate(data)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "refined-mailman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['dog', 'bites', 'man'], tags=['0']),\n",
       " TaggedDocument(words=['man', 'bites', 'dog'], tags=['1']),\n",
       " TaggedDocument(words=['dog', 'eats', 'meat'], tags=['2']),\n",
       " TaggedDocument(words=['man', 'eats', 'food'], tags=['3'])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "crude-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dbow\n",
    "model_dbow = Doc2Vec(tagged_data,vector_size=20, min_count=1, epochs=2,dm=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "signal-component",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02145586 -0.00096876  0.00553643 -0.00445745 -0.02109203  0.0222741\n",
      "  0.02425783 -0.00968846  0.01910269  0.02105233  0.00661557  0.00089649\n",
      "  0.02295156  0.01016324  0.01208203  0.00454688 -0.004014    0.00417333\n",
      " -0.01654172  0.01886915]\n"
     ]
    }
   ],
   "source": [
    "print(model_dbow.infer_vector(['man','eats','food']))#feature vector of man eats food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "defensive-lyric",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('meat', 0.3246762454509735),\n",
       " ('food', 0.16220729053020477),\n",
       " ('bites', 0.14827197790145874),\n",
       " ('dog', -0.044396281242370605),\n",
       " ('eats', -0.14157932996749878)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dbow.wv.most_similar(\"man\",topn=5)#top 5 most simlar words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "chinese-lexington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0443963"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dbow.wv.n_similarity([\"dog\"],[\"man\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "third-student",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Vector of man eats food\n",
      "  [-0.02145578 -0.0009689   0.00553642 -0.00445757 -0.02109202  0.02227421\n",
      "  0.02425792 -0.00968847  0.01910283  0.02105243  0.00661543  0.00089652\n",
      "  0.02295154  0.01016334  0.01208198  0.00454681 -0.00401392  0.00417328\n",
      " -0.01654172  0.01886907]\n",
      "Most similar words to man in our corpus\n",
      " [('meat', 0.3246762454509735), ('food', 0.16220729053020477), ('bites', 0.14827197790145874), ('dog', -0.044396281242370605), ('eats', -0.14157932996749878)]\n",
      "Similarity between man and dog:  -0.0443963\n"
     ]
    }
   ],
   "source": [
    "#dm\n",
    "model_dm = Doc2Vec(tagged_data, min_count=1, vector_size=20, epochs=2,dm=1)\n",
    "\n",
    "print(\"Inference Vector of man eats food\\n \",model_dm.infer_vector(['man','eats','food']))\n",
    "\n",
    "print(\"Most similar words to man in our corpus\\n\",model_dm.wv.most_similar(\"man\",topn=5))\n",
    "print(\"Similarity between man and dog: \",model_dm.wv.n_similarity([\"dog\"],[\"man\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "funded-ceremony",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'covid' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-21897cb372b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_dm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'covid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'man'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/marcos/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mn_similarity\u001b[0;34m(self, ws1, ws2)\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mZeroDivisionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'At least one of the passed list is empty.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m         \u001b[0mv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mws1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m         \u001b[0mv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mws2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munitvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munitvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marcos/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mZeroDivisionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'At least one of the passed list is empty.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m         \u001b[0mv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mws1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m         \u001b[0mv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mws2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munitvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munitvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marcos/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marcos/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marcos/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'covid' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "model_dm.wv.n_similarity(['covid'],['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-mozambique",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-belly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-boring",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-beaver",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-evolution",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
